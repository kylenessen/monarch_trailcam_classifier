## Prep monarch count data

Here I am loading in the available count data so far. SC1 and SC2 are the only deployments with a 5 minute interval, so I am removing every other row initially to get it to 10 mins. Then I append SC4, which is more typical.

```{r}
library(tidyverse)

data_directory <- "data/"
csv_files <- c("SC1.csv", "SC2.csv") # Load the 5 min interval datasets

df <- csv_files %>%
    map_df(~ read_csv(file.path(data_directory, .))) %>%
    mutate(time = ymd_hms(timestamp, tz = "America/Los_Angeles")) %>%
    arrange(deployment_id, time) %>%
    group_by(deployment_id) %>%
    filter(row_number() %% 2 == 1) %>% # Keep every other row (odd numbered rows)
    ungroup() %>%
    as_tibble()

# Read SC4 data and process it similarly to the other files
SC4 <- read.csv("data/SC4.csv") %>%
    mutate(time = ymd_hms(timestamp, tz = "America/Los_Angeles")) %>%
    as_tibble()

# Combine all data
df <- bind_rows(df, SC4) %>%
    arrange(deployment_id, time) %>%
    mutate(
        day = as.Date(time, tz = "America/Los_Angeles"),
        observation_period = paste(deployment_id, day)
    )
```

## Remove night photos

Night photos are difficult to see the butterflies, so we simply copy and pasted the last valid count until we can see them again. This will affect our stats, of course, so I am going to remove them here.

```{r}
# Define night periods for each deployment
# Format: "YYYY-MM-DD HH:MM:SS"
night_periods <- list(
    SC1 = list(
        # Night 1
        list(
            start = "20231117174001",
            end = "20231118062001"
        ),
        # Night 2
        list(
            start = "20231118172501",
            end = "20231119061501"
        ),
        # Night 3
        list(
            start = "20231119171001",
            end = "20231120062001"
        )
    ),
    SC2 = list(
        # Night 1
        list(
            start = "20231117172501",
            end = "20231118062001"
        ),
        # Night 2
        list(
            start = "20231118171501",
            end = "20231119061501"
        )
    ),
    SC4 = list(
        # Night 1
        list(
            start = "20231203171001",
            end = "20231204063001"
        )
    )
)

# Function to check if a timestamp falls within any night period
is_night_time <- function(timestamp, deployment_periods) {
    any(sapply(deployment_periods, function(period) {
        timestamp >= ymd_hms(period$start, tz = "America/Los_Angeles") &
            timestamp <= ymd_hms(period$end, tz = "America/Los_Angeles")
    }))
}

# Filter out night periods from the dataframe
df <- df %>%
    group_by(deployment_id) %>%
    filter(!mapply(
        function(t, d) is_night_time(t, night_periods[[d]]),
        time,
        deployment_id
    )) %>%
    ungroup()

```

## Generate the subsampled datasets

Here I split out the original df into my test dataset. I'm going to go with 10, 20, 30, 60, 90, and 120 minutes. They will be named accordingly.

```{r}
# 10 minutes (keep all rows)
df10 <- df

# 20 minutes (keep every other row)
df20 <- df %>%
    group_by(deployment_id) %>%
    filter(row_number() %% 2 == 1) %>%
    ungroup()

# 30 minutes (keep every third row)
df30 <- df %>%
    group_by(deployment_id) %>%
    filter(row_number() %% 3 == 1) %>%
    ungroup()

# 60 minutes (keep every sixth row)
df60 <- df %>%
    group_by(deployment_id) %>%
    filter(row_number() %% 6 == 1) %>%
    ungroup()

# 90 minutes (keep every ninth row)
df90 <- df %>%
    group_by(deployment_id) %>%
    filter(row_number() %% 9 == 1) %>%
    ungroup()

# 120 minutes (keep every twelfth row)
df120 <- df %>%
    group_by(deployment_id) %>%
    filter(row_number() %% 12 == 1) %>%
    ungroup()
```

## Calculate change in monarch counts for each dataset

Here I define a function to calculate the change in monarch butterfly abundance and then apply it to all of my datasets. Changes of zero are replaced with 0.1 before log transformation.

```{r}
# Function to calculate monarch count changes
calculate_monarch_changes <- function(df) {
    df %>%
        arrange(deployment_id, time) %>%
        group_by(deployment_id) %>%
        mutate(
            prev_count = lag(count),
            raw_change = count - prev_count,
            # Replace zero changes with 0.1 before log transform
            change_for_log = ifelse(raw_change == 0, 0.1, raw_change),
            monarch_change = log(abs(change_for_log)) * sign(change_for_log),
            time_diff_minutes = as.numeric(difftime(time, lag(time), units = "mins"))
        ) %>%
        ungroup()
}

# Apply the function to each dataset
df10 <- calculate_monarch_changes(df10)
df20 <- calculate_monarch_changes(df20)
df30 <- calculate_monarch_changes(df30)
df60 <- calculate_monarch_changes(df60)
df90 <- calculate_monarch_changes(df90)
df120 <- calculate_monarch_changes(df120)
```

## Calculate wind parameters between intervals

Here I calculate wind metric summaries between butterfly observations

```{r}
# Load wind data
wind <- read_csv("https://raw.githubusercontent.com/kylenessen/masters-wind-data/main/vsfb/vsfb_wind_data.csv")

# Helper function to create empty wind summary
create_empty_wind_summary <- function() {
    tibble(
        avg_wind_speed_mph = NA_real_,
        avg_wind_gust_mph = NA_real_,
        max_wind_gust_mph = NA_real_,
        n_wind_obs = 0L
    )
}

# Function to add interval timestamps to a dataframe
add_intervals <- function(df) {
    df %>%
        arrange(deployment_id, time) %>%
        group_by(deployment_id) %>%
        mutate(
            interval_end = time,
            interval_start = lag(time)
        ) %>%
        ungroup()
}

# Function to calculate wind metrics between intervals
calculate_wind_metrics <- function(deploy_id, start_time, end_time) {
    # Return NA values if start time is missing
    if (is.na(start_time)) {
        return(create_empty_wind_summary())
    }

    # Filter wind data for the interval
    wind_interval <- wind %>%
        filter(
            deployment_id == deploy_id,
            time >= start_time,
            time <= end_time
        )

    # Return NA values if no wind observations found
    if (nrow(wind_interval) == 0) {
        return(create_empty_wind_summary())
    }

    # Calculate wind metrics
    wind_interval %>%
        summarize(
            avg_wind_speed_mph = mean(speed_mph, na.rm = TRUE),
            avg_wind_gust_mph = mean(gust_mph, na.rm = TRUE),
            max_wind_gust_mph = max(gust_mph, na.rm = TRUE),
            n_wind_obs = n()
        )
}

# Main function to add wind metrics to a dataframe
add_wind_metrics <- function(df) {
    # Add interval timestamps
    df_with_intervals <- add_intervals(df)

    # Calculate wind summaries
    wind_summaries <- pmap_dfr(
        list(
            deploy_id = df_with_intervals$deployment_id,
            start_time = df_with_intervals$interval_start,
            end_time = df_with_intervals$interval_end
        ),
        calculate_wind_metrics
    )

    # Combine original data with wind summaries
    bind_cols(df_with_intervals, wind_summaries)
}

# Apply wind metrics calculation to each dataset
df10 <- add_wind_metrics(df10)
df20 <- add_wind_metrics(df20)
df30 <- add_wind_metrics(df30)
df60 <- add_wind_metrics(df60)
df90 <- add_wind_metrics(df90)
df120 <- add_wind_metrics(df120)
```

## Modeling

The fun part! Let's build a model. `monarch_change` will be the response variable. Our fixed effects are the wind variables: `avg_wind_speed_mph`, `avg_wind_gust_mph`, `max_wind_gust_mph`. Our only random effect is `deployment_id`. I want to also correct for temporal autocorrelation using either `time` (if datetime objects are useful) or `timestamp` if some numerical value must be used.

Let's build this model for all of our subsampled datasets and compare AIC scores

```{r}
# Load required packages for mixed effects models and temporal autocorrelation
library(lme4)
library(nlme)
library(lubridate)

# Function to prepare data for modeling by removing NA values and scaling predictors
prepare_data <- function(df) {
    df %>%
        filter(
            !is.na(monarch_change), !is.na(avg_wind_speed_mph),
            !is.na(avg_wind_gust_mph), !is.na(max_wind_gust_mph)
        ) %>%
        mutate(
            # Scale wind variables
            avg_wind_speed_scaled = scale(avg_wind_speed_mph),
            avg_wind_gust_scaled = scale(avg_wind_gust_mph),
            max_wind_gust_scaled = scale(max_wind_gust_mph),
            # Create numeric time variable for autocorrelation
            time_numeric = as.numeric(time)
        )
}

# Function to fit model and extract AIC
fit_model <- function(df, interval) {
    # Prepare data
    model_data <- prepare_data(df)

    # Fit model with temporal correlation structure
    model <- try(
        {
            lme(monarch_change ~ avg_wind_speed_scaled + avg_wind_gust_scaled + max_wind_gust_scaled,
                random = ~ 1 | deployment_id,
                correlation = corAR1(form = ~ time_numeric | deployment_id),
                data = model_data,
                method = "REML"
            )
        },
        silent = TRUE
    )

    # Extract model results
    if (!inherits(model, "try-error")) {
        # Extract fixed effects
        fixed_effects <- fixef(model)
        # Extract random effects variance
        random_effects_var <- as.numeric(VarCorr(model)[1, 1])
        # Get correlation parameter
        corr_param <- coef(model$modelStruct$corStruct, unconstrained = FALSE)
        # Calculate AIC
        aic <- AIC(model)

        # Return results
        list(
            interval = interval,
            converged = TRUE,
            AIC = aic,
            fixed_effects = fixed_effects,
            random_effects_var = random_effects_var,
            correlation = corr_param,
            n_obs = nrow(model_data),
            model = model
        )
    } else {
        # Return NA values if model fails
        list(
            interval = interval,
            converged = FALSE,
            AIC = NA,
            fixed_effects = NA,
            random_effects_var = NA,
            correlation = NA,
            n_obs = nrow(model_data),
            model = NA
        )
    }
}

# Fit models for each dataset
results_10 <- fit_model(df10, 10)
results_20 <- fit_model(df20, 20)
results_30 <- fit_model(df30, 30)
results_60 <- fit_model(df60, 60)
results_90 <- fit_model(df90, 90)
results_120 <- fit_model(df120, 120)

# Combine results into a data frame
model_comparison <- tibble(
    Interval = c(10, 20, 30, 60, 90, 120),
    AIC = c(
        results_10$AIC, results_20$AIC, results_30$AIC,
        results_60$AIC, results_90$AIC, results_120$AIC
    ),
    N = c(
        results_10$n_obs, results_20$n_obs, results_30$n_obs,
        results_60$n_obs, results_90$n_obs, results_120$n_obs
    ),
    Converged = c(
        results_10$converged, results_20$converged, results_30$converged,
        results_60$converged, results_90$converged, results_120$converged
    )
)

# Display model comparison results
print("Model Comparison Results:")
print(model_comparison)

# Save model comparison results to CSV
write.csv(model_comparison, "figures/model_comparison.csv", row.names = FALSE)

# Plot AIC scores
aic_plot <- ggplot(model_comparison, aes(x = Interval, y = AIC)) +
    geom_line() +
    geom_point() +
    labs(
        title = "AIC Scores by Sampling Interval",
        x = "Sampling Interval (minutes)",
        y = "AIC Score"
    ) +
    theme_minimal()

# Save the plot
ggsave("figures/aic_scores.png", aic_plot, width = 8, height = 6, dpi = 300)

# Display detailed results for the best model (lowest AIC)
best_model_idx <- which.min(model_comparison$AIC)
best_interval <- model_comparison$Interval[best_model_idx]
best_model <- get(paste0("results_", best_interval))

print(paste("\nBest Model (", best_interval, "minute interval):"))
print(summary(best_model$model))

# Plot residuals vs fitted values for best model
plot(best_model$model, which = 1)
```

## Fast Fourier Transform (FFT)
The AIC approach didn't work as we might expected. So after a little bit of looking around, I came across this fast Fourier transformation. I believe what this will do is fit a line to the data and then calculate a curve that we can compare against each other.


```{r}
compute_fft <- function(df) {
    df %>%
        group_by(deployment_id, observation_period) %>%
        summarize(
            fft_magnitude = abs(fft(count)), # Compute magnitude of FFT
            fft_frequency = seq(0, length(fft_magnitude) - 1) / length(fft_magnitude) # Normalized frequency
        ) %>%
        ungroup()
}

fft_full <- compute_fft(df10)
fft_20 <- compute_fft(df20)
fft_30 <- compute_fft(df30)
fft_60 <- compute_fft(df60)
fft_90 <- compute_fft(df90)
fft_120 <- compute_fft(df120)
```


```{r}
ks_test_results <- list(
    df20 = ks.test(fft_full$fft_magnitude, fft_20$fft_magnitude),
    df30 = ks.test(fft_full$fft_magnitude, fft_30$fft_magnitude),
    df60 = ks.test(fft_full$fft_magnitude, fft_60$fft_magnitude),
    df90 = ks.test(fft_full$fft_magnitude, fft_90$fft_magnitude),
    df120 = ks.test(fft_full$fft_magnitude, fft_120$fft_magnitude)
)

# Extract p-values
ks_p_values <- tibble(
    Interval = c(20, 30, 60, 90, 120),
    P_Value = c(
        ks_test_results$df20$p.value,
        ks_test_results$df30$p.value,
        ks_test_results$df60$p.value,
        ks_test_results$df90$p.value,
        ks_test_results$df120$p.value
    )
)

# Flag significant differences
ks_p_values <- ks_p_values %>%
    mutate(Significant = P_Value < 0.05)

print(ks_p_values)

```


```{r}
library(ggplot2)

plot_fft <- function(full, subsampled, label) {
    ggplot() +
        geom_line(aes(x = full$fft_frequency, y = full$fft_magnitude, color = "Full Resolution")) +
        geom_line(aes(x = subsampled$fft_frequency, y = subsampled$fft_magnitude, color = label)) +
        scale_color_manual(values = c("Full Resolution" = "black", label = "red")) +
        labs(
            title = paste("FFT Comparison:", label, "vs. Full Resolution"),
            x = "Frequency",
            y = "Magnitude"
        ) +
        theme_minimal()
}

plot_fft(fft_full, fft_20, "20-min Interval")
plot_fft(fft_full, fft_30, "30-min Interval")
plot_fft(fft_full, fft_60, "60-min Interval")
plot_fft(fft_full, fft_90, "90-min Interval")
plot_fft(fft_full, fft_120, "120-min Interval")

```


```{r}
ggplot(ks_p_values, aes(x = factor(Interval), y = P_Value, fill = Significant)) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "green")) +
    labs(
        title = "Statistical Test: FFT Similarity to Full Resolution",
        x = "Sampling Interval (minutes)",
        y = "Kolmogorov-Smirnov P-Value"
    ) +
    theme_minimal()

```